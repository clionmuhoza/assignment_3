{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install idx2numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU87kuUjTfzs",
        "outputId": "f28b445b-baa6-43fc-83b8-68efdc68af88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: idx2numpy in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A57IpaVSfp8",
        "outputId": "600e5a15-0d05-47da-b31f-e63c11e22171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5135, Accuracy: 86.73%\n",
            "Epoch [2/10], Loss: 0.3274, Accuracy: 89.13%\n",
            "Epoch [3/10], Loss: 0.2827, Accuracy: 90.20%\n",
            "Epoch [4/10], Loss: 0.2524, Accuracy: 90.46%\n",
            "Epoch [5/10], Loss: 0.2283, Accuracy: 90.99%\n",
            "Epoch [6/10], Loss: 0.2084, Accuracy: 90.99%\n",
            "Epoch [7/10], Loss: 0.1897, Accuracy: 91.89%\n",
            "Epoch [8/10], Loss: 0.1736, Accuracy: 91.91%\n",
            "Epoch [9/10], Loss: 0.1602, Accuracy: 91.88%\n",
            "Epoch [10/10], Loss: 0.1461, Accuracy: 92.00%\n",
            "Model saved to /content/simple_cnn_model.pt\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import idx2numpy\n",
        "import requests\n",
        "import gzip\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from torchvision import transforms\n",
        "\n",
        "# Custom dataset class for FashionMNIST with normalization\n",
        "class FashionImagesDataset(Dataset):\n",
        "    def __init__(self, img_url, lbl_url, transform=None):\n",
        "        self.img_data = self.fetch_and_extract(img_url)\n",
        "        self.lbl_data = self.fetch_and_extract(lbl_url)\n",
        "        self.transform = transform\n",
        "\n",
        "    def fetch_and_extract(self, url):\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        with gzip.GzipFile(fileobj=BytesIO(response.content)) as f:\n",
        "            return idx2numpy.convert_from_file(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_data[idx].reshape(1, 28, 28) / 255.0  # Normalize to [0,1]\n",
        "        img = torch.tensor(img, dtype=torch.float32)\n",
        "        label = self.lbl_data[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# URLs for dataset\n",
        "train_imgs_url = \"https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-images-idx3-ubyte.gz\"\n",
        "train_lbls_url = \"https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/train-labels-idx1-ubyte.gz\"\n",
        "test_imgs_url = \"https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-images-idx3-ubyte.gz\"\n",
        "test_lbls_url = \"https://github.com/zalandoresearch/fashion-mnist/raw/master/data/fashion/t10k-labels-idx1-ubyte.gz\"\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Normalize((0.5,), (0.5,))  # Normalizing images to mean 0.5 and std 0.5\n",
        "\n",
        "# Load the data with transformations\n",
        "train_data = FashionImagesDataset(train_imgs_url, train_lbls_url, transform=transform)\n",
        "test_data = FashionImagesDataset(test_imgs_url, test_lbls_url, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
        "\n",
        "# Define a simpler CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define training and evaluation functions\n",
        "def train_model(model, train_loader, test_loader, epochs=10, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Evaluate the model after each epoch\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += targets.size(0)\n",
        "                correct += (predicted == targets).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # Save the model\n",
        "    torch.save(model.state_dict(), \"/content/simple_cnn_model.pt\")\n",
        "    print(\"Model saved to /content/simple_cnn_model.pt\")\n",
        "\n",
        "# Instantiate and train the simpler model\n",
        "model = SimpleCNN()\n",
        "train_model(model, train_loader, test_loader, epochs=10, lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "\n",
        "# URL for the model checkpoint on GitHub\n",
        "model_url = \"https://github.com/clionmuhoza/assignment_3/raw/main/simple_cnn_model.pt\"\n",
        "\n",
        "# Load the model from a checkpoint on GitHub\n",
        "def load_checkpoint_from_url(model_class, url, lr=0.001):\n",
        "    # Download the model checkpoint from GitHub\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(\"downloaded_checkpoint.pt\", \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    # Load the checkpoint and inspect its structure\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    checkpoint = torch.load(\"downloaded_checkpoint.pt\", map_location=device)\n",
        "\n",
        "    # Print the keys to see what is available in the checkpoint\n",
        "    print(\"Checkpoint keys:\", checkpoint.keys())\n",
        "\n",
        "    # Instantiate the model and optimizer\n",
        "    model = model_class().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Check if 'model_state_dict' key is in the checkpoint\n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint.get('epoch', 0)\n",
        "        print(f\"Model loaded from {url}, resuming from epoch {start_epoch}\")\n",
        "    else:\n",
        "        # If checkpoint only has model weights (no optimizer or epoch info)\n",
        "        model.load_state_dict(checkpoint)\n",
        "        start_epoch = 0\n",
        "        print(f\"Model weights loaded from {url} without optimizer or epoch info. Starting from epoch {start_epoch}\")\n",
        "\n",
        "    return model, optimizer, start_epoch\n",
        "\n",
        "# Example\n",
        "# Load the model, optimizer, and starting epoch from GitHub\n",
        "model, optimizer, start_epoch = load_checkpoint_from_url(SimpleCNN, model_url, lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iTdzfOpShRz",
        "outputId": "7606c84f-1525-444f-d902-dc4f6ff1224b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint keys: odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n",
            "Model weights loaded from https://github.com/clionmuhoza/assignment_3/raw/main/simple_cnn_model.pt without optimizer or epoch info. Starting from epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3514f04cec17>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"downloaded_checkpoint.pt\", map_location=device)\n"
          ]
        }
      ]
    }
  ]
}